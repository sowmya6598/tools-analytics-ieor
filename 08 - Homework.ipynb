{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f4bc5b",
   "metadata": {},
   "source": [
    "# Homework 8: HTTP, REST APIs, Data Formats\n",
    "\n",
    "You may use the following packages/imports for any of the questions below:\n",
    "\n",
    "* `bs4` ([docs](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) - should already be installed with Anaconda) \n",
    "* `requests` ([docs](https://docs.python-requests.org/en/latest/) - should already be installed with Anaconda)\n",
    "* `json` (standard library)\n",
    "* `re` (standard library)\n",
    "\n",
    "Total questions: 5<br/>\n",
    "Total points: 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0bbe7",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Write a function called `get_api_header_data` that calls `http://numbersapi.com/21/trivia`, and returns a `dict` of the following keys, with the values found in the response's headers:\n",
    "\n",
    "* `\"Server\"`\n",
    "* `\"Content-Type\"`\n",
    "* `\"Content-Length\"`\n",
    "\n",
    "[1 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df8a74fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_api_header_data() -> dict:\n",
    "    resp = requests.get(\"http://numbersapi.com/21/trivia\")\n",
    "    return {\n",
    "        \"Server\": resp.headers[\"Server\"],\n",
    "        \"Content-Type\": resp.headers[\"Content-Type\"],\n",
    "        \"Content-Length\": resp.headers[\"Content-Length\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee11db0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograder tests\n",
    "\n",
    "# Ensure the returned result is a dictionary\n",
    "result = get_api_header_data()\n",
    "assert isinstance(result, dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94612395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograder tests\n",
    "# Ensure the expected results are returned\n",
    "actual = get_api_header_data()\n",
    "assert \"nginx/1.4.6 (Ubuntu)\" == actual[\"Server\"]\n",
    "assert \"text/plain; charset=utf-8\" == actual[\"Content-Type\"]\n",
    "\n",
    "# Content-Length is variable depending on the number of characters in the fact,\n",
    "# but it should be able to be casted into an integer.\n",
    "assert isinstance(int(actual[\"Content-Length\"]), int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b73948",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Write a function called `post_data` that takes one argument, `data` (a dictionary), and returns a `requests.Response` object.\n",
    "\n",
    "This function should submit a `POST` request to the url `https://httpbin.org/post`. The request should post the `data` argument as JSON. It should also set the headers `\"Content-Type\"` and `\"Accept\"` to the appropriate [MIME type](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types) for sending JSON data. Finally, it should return the response received from the post request.\n",
    "\n",
    "[2 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62d5d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def post_data(data):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "    resp = requests.post(\"https://httpbin.org/post\", headers=headers, json=data)\n",
    "    # also accepted:\n",
    "    # data = json.dumps(data)\n",
    "    # resp = requests.post(\"https://httpbin.org/post\", headers=headers, data=data)\n",
    "    return resp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5600bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograder tests\n",
    "result = post_data({\"foo\": \"bar\", \"baz\": \"blah\"})\n",
    "\n",
    "# Ensure the correct type is returned\n",
    "assert isinstance(result, requests.Response)\n",
    "\n",
    "# Ensure the correct request method was used\n",
    "assert \"POST\" == result.request.method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6260cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograder tests\n",
    "result = post_data({\"foo\": \"bar\", \"baz\": \"blah\"})\n",
    "json_data = json.dumps({\"foo\": \"bar\", \"baz\": \"blah\"})\n",
    "exp_req_headers = {\n",
    "    \"Content-Length\": str(len(json_data)),\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Ensure the correct headers were sent in the request\n",
    "for exp_key, exp_val in exp_req_headers.items():\n",
    "    assert exp_val == result.request.headers[exp_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b23b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograder tests\n",
    "result = post_data({\"foo\": \"bar\", \"baz\": \"blah\"})\n",
    "\n",
    "# Ensure the data is sent as JSON and not altered\n",
    "act_resp_json = result.json()[\"json\"]\n",
    "assert {\"foo\": \"bar\", \"baz\": \"blah\"} == act_resp_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d5beb0",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Define a function called `get_html` that returns an HTML string. The HTML returned should contain the following HTML elements:\n",
    "\n",
    "* Three paragraphs\n",
    "* One photo\n",
    "* Three hypertext reference link\n",
    "\n",
    "The paragraphs and link elements must contain content. The HTML returned must be valid HTML (you can use [this HTML validator](https://validator.w3.org/nu/#textarea) to check if your HTML is valid), and must contain all necessary container tags.\n",
    "\n",
    "[2 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d36fd0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html():\n",
    "    return \"\"\"\n",
    "    <!doctype html>\n",
    "    <html lang=en>\n",
    "        <head>\n",
    "            <meta charset=utf-8>\n",
    "            <title>My Title</title>\n",
    "        </head>\n",
    "        <body>\n",
    "            <img src=\"test.jpg\">\n",
    "            <p>I'm some content. <a class=\"large\" href=\"https://www.google.com\">link2</a></p>\n",
    "            <p>\n",
    "                <a class=\"large\" href=\"https://www.google.com\">link1</a>\n",
    "            </p>\n",
    "            <p>\n",
    "                Some content. <a class=\"large\" href=\"https://www.google.com\">link3</a>\n",
    "            </p>\n",
    "        </body>\n",
    "    </html>\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8db0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograder tests\n",
    "# Ensure the HTML has the correct header\n",
    "html = get_html()\n",
    "# first normalize possible correct implementations\n",
    "cleaned_html = ' '.join(html.split()).strip().lower()\n",
    "# then assert that it starts with the expected header\n",
    "assert cleaned_html.startswith(\"<!doctype html>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d84445fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograder tests\n",
    "import bs4\n",
    "\n",
    "soup = bs4.BeautifulSoup(get_html(), 'html.parser')\n",
    "\n",
    "# Ensure there's a `<head>` tag with a title set for the website\n",
    "assert len(soup.find_all('title')) == 1\n",
    "assert soup.find('title').parent.name.lower() == 'head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41919fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograder tests\n",
    "# Ensure there are three links, and three paragraphs\n",
    "assert len(soup.find_all('a')) == 3\n",
    "assert len(soup.find_all('p')) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e87cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograder tests\n",
    "assert len(soup.find_all('img')) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be6a68",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Write a function called `ones` which takes two arguments, `m` and `n`, and produces an `m` row by `n` column JSON array-of-arrays, with all elements being 1.\n",
    "\n",
    "For example:\n",
    "\n",
    "```py\n",
    ">>> ones(2, 2)\n",
    "'[[1, 1], [1, 1]]'\n",
    "```\n",
    "\n",
    "Another example:\n",
    "\n",
    "```py\n",
    ">>> ones(1, 4)\n",
    "'[[1, 1, 1, 1]]'\n",
    "```\n",
    "\n",
    "You may assume that `m` and `n` will only ever be a positive integer.\n",
    "\n",
    "[1 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e4406f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def ones(m, n):\n",
    "    return json.dumps([[1] * n] * m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16a5617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograder tests\n",
    "assert json.loads(ones(2, 2)) == [[1, 1], [1, 1]]\n",
    "assert json.loads(ones(1, 4)) == [[1, 1, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48801649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograder tests\n",
    "assert json.loads(ones(3, 2)) == [[1, 1], [1, 1], [1, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ac2127",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "As practice to help prepare your final project, write a function called `find_taxi_parquet_links`. It should call the `get_taxi_html` function already defined for you (which returns the entire HTML of the NYC taxi data website used for your final project), and returns a `list` of `str`s of all links for _both_ Yellow and Green taxi trip records. \n",
    "\n",
    "Use BeautifulSoup to parse the HTML returned by `get_taxi_html`. Do not include any other types of links, including for-hire vehicle trip records.\n",
    "\n",
    "[2 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6117500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "\n",
    "\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "\n",
    "def get_taxi_html():\n",
    "    response = requests.get(TAXI_URL)\n",
    "    html = response.content\n",
    "    return html\n",
    "\n",
    "\n",
    "def find_taxi_parquet_links():\n",
    "    ### BEGIN SOLUTION\n",
    "    html = get_taxi_html()\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    green_a_tags = soup.find_all(\"a\", attrs={\"title\": \"Green Taxi Trip Records\"})\n",
    "    yellow_a_tags = soup.find_all(\"a\", attrs={\"title\": \"Yellow Taxi Trip Records\"})\n",
    "    all_a_tags = green_a_tags + yellow_a_tags\n",
    "    return [a[\"href\"] for a in all_a_tags]\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dabc4101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograder tests\n",
    "result = find_taxi_parquet_links()\n",
    "\n",
    "# Ensure the returned results are the expected type,\n",
    "assert isinstance(result, list)\n",
    "assert len(result) > 0\n",
    "assert isinstance(result[0], str)\n",
    "\n",
    "# Ensure the number of returned results;\n",
    "# Since they regularly update the site with new monthly data,\n",
    "# this is only a rough approximation.\n",
    "assert len(result) >= 269\n",
    "assert len(result) < 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf997d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograder tests\n",
    "import re\n",
    "\n",
    "result = find_taxi_parquet_links()\n",
    "\n",
    "pattern = re.compile(\n",
    "    r\"(green|yellow)_tripdata_20([0-9]{2})-([0-9]{2}).parquet\"\n",
    ")\n",
    "expected = []\n",
    "for link in result:\n",
    "    match = pattern.search(link)\n",
    "    if match:\n",
    "        expected.append(match.string)\n",
    "\n",
    "assert len(result) == len(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "339c60c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autograder tests\n",
    "import re\n",
    "\n",
    "result = find_taxi_parquet_links()\n",
    "result = sorted(result)\n",
    "\n",
    "# Just spot check a couple links\n",
    "expected0 = \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2013-08.parquet\"\n",
    "expected180 = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-09.parquet\"\n",
    "expected268 = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet\"\n",
    "\n",
    "assert expected0 == result[0], result[0]\n",
    "assert expected180 == result[180], result[180]\n",
    "assert expected268 == result[268], result[268]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
